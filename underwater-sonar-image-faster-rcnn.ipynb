{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install --upgrade tf-slim"],"metadata":{"id":"A0TW_epNsctB"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW2W17o-p7SX"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL"},"source":["# If you forked the repo, you can replace the link.\n","repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n","\n","# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n","num_steps = 10000  # 200000 to improve\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","selected_model = 'faster_rcnn_inception_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z"},"source":["import os\n","\n","%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNfIPc5yxDOv"},"source":["%cd /content/tensorflow-object-detection-faster-rcnn/data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yb_FMcfnSbRZ"},"source":["# UPDATE THIS LINK - get our data from Roboflow\n","!curl -L \"https://app.roboflow.com/ds/aBUAM9dP8Q?key=OsRiwZWvJD\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7T58u1YP9sUW"},"source":["%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5qhOGaTTFsq"},"source":["# check out what we have\n","%cd train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_1SbvmATHk-"},"source":["# list contents\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV"},"source":["# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n","test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/valid/3.tfrecord'\n","train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/3.tfrecord'\n","label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/3_label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGhvAObeiIix"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU"},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fG1nCNpUXcRU"},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI"},"source":["import re\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6"},"source":["!cat {pipeline_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f11w0uO3jFCB"},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0H2PZs-mSCmO"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8o6r1o5SC5M"},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge1OX7gcSC7S"},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjhPT9iPSJ6T"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nC7_syR1SJ9F"},"source":["!pip install lvis\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5"},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs"},"source":["!ls {model_dir}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq"},"source":["import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD"},"source":["!ls {output_directory}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr"},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHqWkLBINYoI"},"source":["!ls -alh {pb_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAqyASIJqjae"},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fname = os.path.basename(pb_fname)\n","# Create & upload a text file.\n","uploaded = drive.CreateFile({'title': fname})\n","uploaded.SetContentFile(pb_fname)\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1TbL6Ox8q6Z"},"source":["from google.colab import files\n","files.download(label_map_pbtxt_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bP0iMMnnr77"},"source":["from google.colab import files\n","files.download(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pql2QpemazE1"},"source":["files.download(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pzj9A4e5mj5l"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/test\")\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNFc5CM3Duav"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CG5YUMdg1Po7"},"source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IbKIjbY_MRk"},"source":["# Output images not showing? Run this cell again, and try the cell above\n","# This is needed to display the images.\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ah9YKYOX9qrH"},"source":["\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Za5Hm6-y3_Vs"},"execution_count":null,"outputs":[]}]}